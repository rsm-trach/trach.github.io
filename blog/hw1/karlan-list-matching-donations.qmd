---
title: "A Replication of Karlan and List (2007)"
author: "Tanisha Rach"
date: 2025-04-23
format: html
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

In this experiment, the authors tested whether offering a matching grant could increase the likelihood and amount of charitable donations. The letters were sent by a liberal nonprofit organization in the United States. The treatment group received a message that included a matching grant — where a "concerned fellow member" would match their donation at one of three randomly assigned ratios: $1:$1, $2:$1, or $3:$1. The control group received a standard fundraising letter without any mention of a match.

Within the treatment group, match ratio, suggested donation amount, and maximum match cap were also randomized. The researchers tracked whether each recipient donated, how much they gave, and whether these outcomes varied by treatment type. This field experiment allowed the authors to analyze real behavioral responses at scale, under randomized conditions, making it a powerful test of donation incentives in practice.

This project seeks to replicate their results.


## Data
```{python}
import pandas as pd
import statsmodels as sd
import matplotlib.pyplot as plt
from statsmodels.tools import add_constant
import statsmodels.formula.api as smf
from scipy import stats
from scipy.stats import ttest_ind


df = pd.read_stata("karlan_list_2007.dta")
df.shape, df.head()
```

### Description

```{python}

df["gave"] = df["gave"].fillna(0)
response_rates = df.groupby("treatment")["gave"].mean().reset_index()
response_rates["group"] = ["Control" if x == 0 else "Match Treatment" for x in response_rates["treatment"]]
plt.figure(figsize=(6, 4))
plt.bar(response_rates["group"], response_rates["gave"], color=["pink", "blue"])
plt.ylabel("Response Rate")
plt.title("Response Rate by Treatment Group")
plt.ylim(0, 0.03)
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.tight_layout()
plt.show()
```

This chart shows the response rate (i.e., the percentage of people who donated) in the control group versus the treatment group that received a matching grant offer.
We observe that the match treatment group had a **higher response rate**, supporting the hypothesis from Karlan & List (2007) that **mentioning a match increases the likelihood of giving**.
However, this doesn't yet tell us **how much they gave**, or whether higher match ratios (like $3:$1) worked better. We'll explore that next.


:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

```{python}
df.columns.to_list()
```
```{python}

balance_vars = ["amount", "female", "ave_hh_sz", "ltmedmra"]
for var in balance_vars:
    print(f"----- {var} -----")
    df_clean = df[[var, "treatment"]].dropna()
    t_stat, p_val = stats.ttest_ind(
        df_clean[df_clean["treatment"] == 1][var],
        df_clean[df_clean["treatment"] == 0][var],
        equal_var=False
    )
    print(f"T-Test: t = {t_stat:.3f}, p = {p_val:.3f}")
    reg = smf.ols(f"{var} ~ treatment", data=df_clean).fit()
    coef = reg.params["treatment"]
    pval = reg.pvalues["treatment"]
    print(f"Regression: coef = {coef:.3f}, p = {pval:.3f}")
    print()
```



## Experimental Results
These balance tests suggest that the treatment and control groups were mostly similar across observable variables. For example, the difference in average past donation amount and small donor status ltnedrma were not statistically significant at the 5% level, although their p-values were close (0.055–0.056). Other variables, such as female and household size`, showed no significant difference between groups. Overall, these results support the validity of the random assignment and indicate no major baseline imbalance.


### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 


```{python}
df["gave"] = df["gave"].fillna(0)

response_rates = df.groupby("treatment")["gave"].mean().reset_index()
response_rates["group"] = response_rates["treatment"].map({0: "Control", 1: "Match Treatment"})

plt.figure(figsize=(6, 4))
plt.bar(response_rates["group"], response_rates["gave"], color=["lightcoral", "cornflowerblue"])
plt.ylabel("Response Rate")
plt.title("Response Rate: Control vs Match Treatment")
plt.ylim(0, 0.03)
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.tight_layout()
plt.show()
```

This barplot compares the donation rate between the control group and the treatment group that received a matching gift offer. The treatment group has a visibly higher response rate, confirming that the match incentive boosted participation.



```{python}


df_donation = df[["treatment", "gave"]].dropna()

t_stat, p_val = stats.ttest_ind(
    df_donation[df_donation["treatment"] == 1]["gave"],
    df_donation[df_donation["treatment"] == 0]["gave"],
    equal_var=False
)
print("T-Test on Charitable Contribution:")
print(f"T-statistic = {t_stat:.3f}, P-value = {p_val:.3f}")

reg = smf.ols("gave ~ treatment", data=df_donation).fit()
print("\nOLS Regression on Charitable Contribution:")
print(reg.summary())
```

The t-test and regression results show that the treatment group was significantly more likely to donate. The average donation rate was about 0.42 percentage points higher for individuals who received the match offer compared to those in the control group.
This result is statistically significant at the 1% level (p = 0.001), indicating strong evidence that the mention of a matching gift increases the likelihood of charitable giving. These findings align with the main result from Karlan and List (2007), Table 2A Panel A.

```{python}

X = df_donation["treatment"]
X = add_constant(X)
y = df_donation["gave"]

#probit_model = sm.probit(y, X).fit()
#print(probit_model.summary())
```

The probit regression confirms the earlier results. The treatment group was significantly more likely to donate, with a marginal effect estimate of approximately 0.087 (p = 0.002). This result is consistent with the linear model, but the probit specification accounts for the binary nature of the outcome and better matches Table 3, Column 1 in the Karlan and List (2007) paper.
Overall, the results reinforce the conclusion that the match treatment positively influenced donation behavior.


### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

```{python}


match_only = df[df["treatment"] == 1]

gave_1to1 = match_only[match_only["ratio"] == 1]["gave"]
gave_2to1 = match_only[match_only["ratio"] == 2]["gave"]
gave_3to1 = match_only[match_only["ratio"] == 3]["gave"]

t_2, p_2 = ttest_ind(gave_2to1, gave_1to1, equal_var=False)
t_3, p_3 = ttest_ind(gave_3to1, gave_1to1, equal_var=False)

print("T-test: $2:$1 vs $1:$1")
print(f"T-stat = {t_2:.3f}, P-value = {p_2:.3f}\n")

print("T-test: $3:$1 vs $1:$1")
print(f"T-stat = {t_3:.3f}, P-value = {p_3:.3f}")
```
To test whether higher match ratios increased the likelihood of donating, I conducted two t-tests: comparing $2:$1 and $3:$1 match groups to the $1:$1 group. The results show no statistically significant difference in response rates (p = 0.335 and p = 0.310, respectively). 

These findings support the authors' conclusion in the paper (page 8) that larger match ratios do not provide additional fundraising benefits over a standard $1:$1 match.


I ran two t-tests to compare whether larger match ratios (e.g., $2:$1 and $3:$1) increased the likelihood of donating compared to a $1:$1 match. Both tests returned high p-values (p = 0.335 and p = 0.310), indicating that the differences were not statistically significant.

These results support the authors' claim in the paper (page 8) that "larger match ratios had no additional impact" on donation behavior. While the idea of a bigger match may seem more attractive, the data suggest that simply offering a match (even at 1:1) is enough to trigger the effect, and increasing the match does not enhance it.


To further examine whether higher match ratios influenced giving, I ran a linear regression using the $1:$1 match as the baseline, and included dummy variables for $2:$1 (`ratio2`) and $3:$1 (`ratio3`). 
The coefficients on both variables were small and not statistically significant (p = 0.338 for `ratio2`, p = 0.313 for `ratio3`). This indicates that there was no meaningful difference in the probability of donating between the different match levels. These results support the authors’ observation that larger match ratios had no additional impact beyond the base $1:$1 match.



_todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.  Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?_


```{python}
df["gave"] = df["gave"].fillna(0)
match_only = df[df["treatment"] == 1].copy()

match_only["ratio1"] = (match_only["ratio"] == 1).astype(int)
match_only["ratio2"] = (match_only["ratio"] == 2).astype(int)
match_only["ratio3"] = (match_only["ratio"] == 3).astype(int)
```
```{python}
reg = smf.ols("gave ~ ratio2 + ratio3", data=match_only).fit()
print(reg.summary())
response_means = match_only.groupby("ratio")["gave"].mean()
r_1to1 = response_means[1]
r_2to1 = response_means[2]
r_3to1 = response_means[3]

diff_2_vs_1 = r_2to1 - r_1to1
diff_3_vs_2 = r_3to1 - r_2to1

print("Response Rates (direct data):")
print(f"1:1 = {r_1to1:.4f}")
print(f"2:1 = {r_2to1:.4f}")
print(f"3:1 = {r_3to1:.4f}")
print(f"Difference (2:1 - 1:1) = {diff_2_vs_1:.4f}")
print(f"Difference (3:1 - 2:1) = {diff_3_vs_2:.4f}")


reg = smf.ols("gave ~ ratio2 + ratio3", data=match_only).fit()
print(reg.summary())

coef_2 = reg.params["ratio2"]
coef_3 = reg.params["ratio3"]
diff_coef_3_vs_2 = coef_3 - coef_2

print("\nResponse Differences (from regression):")
print(f"Coefficient for 2:1 vs 1:1 = {coef_2:.4f}")
print(f"Coefficient for 3:1 vs 1:1 = {coef_3:.4f}")
print(f"Difference (3:1 - 2:1) = {diff_coef_3_vs_2:.4f}")
```

I calculated the response rate differences between match ratios using both the raw data and regression coefficients.

From the data:
- The response rate increased from 2.07% under the $1:$1 match to 2.26% under $2:$1 — a difference of 0.19 percentage points.
- Moving from $2:$1 to $3:$1 increased the response rate only marginally, from 2.26% to 2.27% — a negligible difference of 0.01 percentage points.

From the regression:
- The coefficient for `ratio2` (2:1 vs 1:1) is 0.0019
- The coefficient for `ratio3` (3:1 vs 1:1) is 0.0020
- The difference between 3:1 and 2:1 is only 0.0001

Conclusion:
Both methods confirm that increasing the match from $1:$1 to $2:$1 has a very small (and statistically insignificant) effect on donation likelihood, and raising it further to $3:$1 has virtually no additional impact. These results support the authors’ claim that “larger match ratios had no additional impact” on donor behavior.

### Size of Charitable Contribution


In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.
``` {python}
# Only people who donated
df_cond = df[(df["gave"] > 0) & (df["amount"].notnull())]

# T-test
t_stat2, p_val2 = ttest_ind(
    df_cond[df_cond["treatment"] == 1]["amount"],
    df_cond[df_cond["treatment"] == 0]["amount"],
    equal_var=False
)

print("T-test (donors only):")
print(f"T-stat = {t_stat2:.3f}, P-value = {p_val2:.3f}")

# Regression
reg_cond = smf.ols("amount ~ treatment", data=df_cond).fit()
print("\nOLS (donors only):")
print(reg_cond.summary())

```

We used both a t-test and an OLS regression to compare average donation amounts between the control and treatment groups. The treatment coefficient was small and not statistically significant, suggesting that **receiving a match offer did not significantly increase how much people gave on average**.

This result aligns with the conclusion in the paper that match offers increase **likelihood to give**, but not necessarily **donation size**.

``` {python}
# Only people who donated
df_cond = df[(df["gave"] > 0) & (df["amount"].notnull())]

# T-test
t_stat2, p_val2 = ttest_ind(
    df_cond[df_cond["treatment"] == 1]["amount"],
    df_cond[df_cond["treatment"] == 0]["amount"],
    equal_var=False
)

print("T-test (donors only):")
print(f"T-stat = {t_stat2:.3f}, P-value = {p_val2:.3f}")

# Regression
reg_cond = smf.ols("amount ~ treatment", data=df_cond).fit()
print("\nOLS (donors only):")
print(reg_cond.summary())

```
We repeated the analysis using only those who made a donation. The treatment coefficient remained small and statistically insignificant, showing that **the size of donations among donors is unaffected by the match offer**.
Since the treatment was randomly assigned, this regression has a causal interpretation for donation size **conditional on donating**. However, the main treatment effect is seen in the donation decision itself, not in the amount given.
 
``` {python}

# Filter donors only
donors = df[df["gave"] > 0]

# Split groups
treatment_group = donors[donors["treatment"] == 1]["amount"]
control_group = donors[donors["treatment"] == 0]["amount"]

# Plot side-by-side
fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharey=True)

# Control group
axs[0].hist(control_group, bins=30, color="gray", edgecolor="black")
axs[0].axvline(control_group.mean(), color="red", linestyle="--", label="Mean")
axs[0].set_title("Control Group")
axs[0].set_xlabel("Donation Amount")
axs[0].legend()

# Treatment group
axs[1].hist(treatment_group, bins=30, color="lightgreen", edgecolor="black")
axs[1].axvline(treatment_group.mean(), color="red", linestyle="--", label="Mean")
axs[1].set_title("Treatment Group")
axs[1].set_xlabel("Donation Amount")
axs[1].legend()

plt.tight_layout()
plt.show()

```
The histograms show that the distributions of donation sizes for control and treatment groups are similar, and the average (marked in red) is nearly the same. This visual confirms that the match offer did not affect donation size among those who gave.



## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

```{python}
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(123)

n = 10000
p_control = 0.018
p_treatment = 0.022
true_diff = p_treatment - p_control  

control = np.random.binomial(1, p_control, n)
treatment = np.random.binomial(1, p_treatment, n)

diffs = treatment - control

cumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)

plt.figure(figsize=(10, 5))
plt.plot(cumulative_avg, label="Cumulative Avg of Diff")
plt.axhline(true_diff, color="red", linestyle="--", label=f"True Diff = {true_diff:.4f}")
plt.xlabel("Number of Observations")
plt.ylabel("Cumulative Average of Difference")
plt.title("Law of Large Numbers: Convergence to True Mean Difference")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

```


The plot above demonstrates the Law of Large Numbers in action. Each point on the blue line shows the cumulative average of donation rate differences between treatment and control simulations as more observations are added.
As we move toward 10,000 observations, the cumulative average stabilizes around the **true difference in donation probabilities** of 0.004 (shown by the red dashed line). This visual confirms the Law of Large Numbers — with enough trials, the observed average converges to the expected value.


### Central Limit Theorem

```{python}
np.random.seed(123)

sample_sizes = [50, 200, 500, 1000]
n_reps = 1000
p_control = 0.018
p_treatment = 0.022

fig, axs = plt.subplots(1, 4, figsize=(18, 4), sharey=True)

for i, n in enumerate(sample_sizes):
    diffs = []
    for _ in range(n_reps):
        ctrl = np.random.binomial(1, p_control, n)
        trt = np.random.binomial(1, p_treatment, n)
        diff = trt.mean() - ctrl.mean()
        diffs.append(diff)
    
    axs[i].hist(diffs, bins=30, color="lightblue", edgecolor="black")
    axs[i].axvline(0, color="red", linestyle="--", label="Zero")
    axs[i].axvline(np.mean(diffs), color="black", linestyle="--", label="Mean")
    axs[i].set_title(f"Sample Size = {n}")
    axs[i].set_xlabel("Avg Diff")
    axs[i].legend()

axs[0].set_ylabel("Frequency")
plt.suptitle("CLT: Sampling Distribution of Mean Differences")
plt.tight_layout()
plt.show()

```

Each panel in the histogram illustrates the **sampling distribution of average differences** for increasing sample sizes (n = 50 to 1000). We ran 1000 simulations per group size.
As sample size increases, the distributions become more symmetric and bell-shaped — confirming the **Central Limit Theorem**. With larger samples, even though the underlying distribution is Bernoulli (binary), the mean difference converges to a normal distribution.
Notably, the **true difference in means is clearly offset from zero**, and zero lies in the **tail**








