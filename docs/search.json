[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "Welcome to my blog! üìö\nHere you‚Äôll find assignments, projects, and reflections on data science, experiments, and more.\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nTanisha Rach\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nTanisha Rach\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/hw2/hw2.html",
    "href": "blog/hw2/hw2.html",
    "title": "HW2",
    "section": "",
    "text": "To be updated."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tanisha Rach",
    "section": "",
    "text": "Here‚Äôs a photograph about me!"
  },
  {
    "objectID": "blog/hw1/karlan-list-matching-donations.html",
    "href": "blog/hw1/karlan-list-matching-donations.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nIn this experiment, the authors tested whether offering a matching grant could increase the likelihood and amount of charitable donations. The letters were sent by a liberal nonprofit organization in the United States. The treatment group received a message that included a matching grant ‚Äî where a ‚Äúconcerned fellow member‚Äù would match their donation at one of three randomly assigned ratios: $1:$1, $2:$1, or $3:$1. The control group received a standard fundraising letter without any mention of a match.\nWithin the treatment group, match ratio, suggested donation amount, and maximum match cap were also randomized. The researchers tracked whether each recipient donated, how much they gave, and whether these outcomes varied by treatment type. This field experiment allowed the authors to analyze real behavioral responses at scale, under randomized conditions, making it a powerful test of donation incentives in practice.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1/karlan-list-matching-donations.html#introduction",
    "href": "blog/hw1/karlan-list-matching-donations.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nIn this experiment, the authors tested whether offering a matching grant could increase the likelihood and amount of charitable donations. The letters were sent by a liberal nonprofit organization in the United States. The treatment group received a message that included a matching grant ‚Äî where a ‚Äúconcerned fellow member‚Äù would match their donation at one of three randomly assigned ratios: $1:$1, $2:$1, or $3:$1. The control group received a standard fundraising letter without any mention of a match.\nWithin the treatment group, match ratio, suggested donation amount, and maximum match cap were also randomized. The researchers tracked whether each recipient donated, how much they gave, and whether these outcomes varied by treatment type. This field experiment allowed the authors to analyze real behavioral responses at scale, under randomized conditions, making it a powerful test of donation incentives in practice.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1/karlan-list-matching-donations.html#data",
    "href": "blog/hw1/karlan-list-matching-donations.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom statsmodels.tools import add_constant\nimport statsmodels.formula.api as smf\nfrom scipy import stats\nfrom scipy.stats import ttest_ind\n\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.shape, df.head()\n\n((50083, 51),\n    treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n 0          0        1  Control       0       0   Control       0       0   \n 1          0        1  Control       0       0   Control       0       0   \n 2          1        0        1       0       0  $100,000       0       0   \n 3          1        0        1       0       0  Unstated       0       0   \n 4          1        0        1       0       0   $50,000       0       1   \n \n    size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n 0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n 1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n 2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n 3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n 4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n \n    ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n 0       2.10          28517.0  0.499807      0.324528            1.0  \n 1        NaN              NaN       NaN           NaN            NaN  \n 2       2.48          51175.0  0.721941      0.192668            1.0  \n 3       2.65          79269.0  0.920431      0.412142            1.0  \n 4       1.85          40908.0  0.416072      0.439965            1.0  \n \n [5 rows x 51 columns])\n\n\n\nDescription\n\ndf[\"gave\"] = df[\"gave\"].fillna(0)\nresponse_rates = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\nresponse_rates[\"group\"] = [\"Control\" if x == 0 else \"Match Treatment\" for x in response_rates[\"treatment\"]]\nplt.figure(figsize=(6, 4))\nplt.bar(response_rates[\"group\"], response_rates[\"gave\"], color=[\"pink\", \"blue\"])\nplt.ylabel(\"Response Rate\")\nplt.title(\"Response Rate by Treatment Group\")\nplt.ylim(0, 0.03)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis chart shows the response rate (i.e., the percentage of people who donated) in the control group versus the treatment group that received a matching grant offer. We observe that the match treatment group had a higher response rate, supporting the hypothesis from Karlan & List (2007) that mentioning a match increases the likelihood of giving. However, this doesn‚Äôt yet tell us how much they gave, or whether higher match ratios (like $3:$1) worked better. We‚Äôll explore that next.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\ndf.columns.to_list()\n\n['treatment',\n 'control',\n 'ratio',\n 'ratio2',\n 'ratio3',\n 'size',\n 'size25',\n 'size50',\n 'size100',\n 'sizeno',\n 'ask',\n 'askd1',\n 'askd2',\n 'askd3',\n 'ask1',\n 'ask2',\n 'ask3',\n 'amount',\n 'gave',\n 'amountchange',\n 'hpa',\n 'ltmedmra',\n 'freq',\n 'years',\n 'year5',\n 'mrm2',\n 'dormant',\n 'female',\n 'couple',\n 'state50one',\n 'nonlit',\n 'cases',\n 'statecnt',\n 'stateresponse',\n 'stateresponset',\n 'stateresponsec',\n 'stateresponsetminc',\n 'perbush',\n 'close25',\n 'red0',\n 'blue0',\n 'redcty',\n 'bluecty',\n 'pwhite',\n 'pblack',\n 'page18_39',\n 'ave_hh_sz',\n 'median_hhincome',\n 'powner',\n 'psch_atlstba',\n 'pop_propurban']\n\n\n\nbalance_vars = [\"amount\", \"female\", \"ave_hh_sz\", \"ltmedmra\"]\nfor var in balance_vars:\n    print(f\"----- {var} -----\")\n    df_clean = df[[var, \"treatment\"]].dropna()\n    t_stat, p_val = stats.ttest_ind(\n        df_clean[df_clean[\"treatment\"] == 1][var],\n        df_clean[df_clean[\"treatment\"] == 0][var],\n        equal_var=False\n    )\n    print(f\"T-Test: t = {t_stat:.3f}, p = {p_val:.3f}\")\n    reg = smf.ols(f\"{var} ~ treatment\", data=df_clean).fit()\n    coef = reg.params[\"treatment\"]\n    pval = reg.pvalues[\"treatment\"]\n    print(f\"Regression: coef = {coef:.3f}, p = {pval:.3f}\")\n    print()\n\n----- amount -----\nT-Test: t = 1.918, p = 0.055\nRegression: coef = 0.154, p = 0.063\n\n----- female -----\nT-Test: t = -1.754, p = 0.080\nRegression: coef = -0.008, p = 0.079\n\n----- ave_hh_sz -----\nT-Test: t = 0.823, p = 0.410\nRegression: coef = 0.003, p = 0.410\n\n----- ltmedmra -----\nT-Test: t = 1.910, p = 0.056\nRegression: coef = 0.009, p = 0.056"
  },
  {
    "objectID": "blog/hw1/karlan-list-matching-donations.html#experimental-results",
    "href": "blog/hw1/karlan-list-matching-donations.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\nThese balance tests suggest that the treatment and control groups were mostly similar across observable variables. For example, the difference in average past donation amount and small donor status ltnedrma were not statistically significant at the 5% level, although their p-values were close (0.055‚Äì0.056). Other variables, such as female and household size`, showed no significant difference between groups. Overall, these results support the validity of the random assignment and indicate no major baseline imbalance.\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\ndf[\"gave\"] = df[\"gave\"].fillna(0)\n\nresponse_rates = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\nresponse_rates[\"group\"] = response_rates[\"treatment\"].map({0: \"Control\", 1: \"Match Treatment\"})\n\nplt.figure(figsize=(6, 4))\nplt.bar(response_rates[\"group\"], response_rates[\"gave\"], color=[\"lightcoral\", \"cornflowerblue\"])\nplt.ylabel(\"Response Rate\")\nplt.title(\"Response Rate: Control vs Match Treatment\")\nplt.ylim(0, 0.03)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis barplot compares the donation rate between the control group and the treatment group that received a matching gift offer. The treatment group has a visibly higher response rate, confirming that the match incentive boosted participation.\n\ndf_donation = df[[\"treatment\", \"gave\"]].dropna()\n\nt_stat, p_val = stats.ttest_ind(\n    df_donation[df_donation[\"treatment\"] == 1][\"gave\"],\n    df_donation[df_donation[\"treatment\"] == 0][\"gave\"],\n    equal_var=False\n)\nprint(\"T-Test on Charitable Contribution:\")\nprint(f\"T-statistic = {t_stat:.3f}, P-value = {p_val:.3f}\")\n\nreg = smf.ols(\"gave ~ treatment\", data=df_donation).fit()\nprint(\"\\nOLS Regression on Charitable Contribution:\")\nprint(reg.summary())\n\nT-Test on Charitable Contribution:\nT-statistic = 3.209, P-value = 0.001\n\nOLS Regression on Charitable Contribution:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        14:18:32   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe t-test and regression results show that the treatment group was significantly more likely to donate. The average donation rate was about 0.42 percentage points higher for individuals who received the match offer compared to those in the control group. This result is statistically significant at the 1% level (p = 0.001), indicating strong evidence that the mention of a matching gift increases the likelihood of charitable giving. These findings align with the main result from Karlan and List (2007), Table 2A Panel A.\n\nimport statsmodels.api as sm \n\nX = sm.add_constant(df_donation[\"treatment\"])\ny = df_donation[\"gave\"]\n\nprobit_model = sm.Probit(y, X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Thu, 24 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        14:18:33   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nThe probit regression confirms the earlier results. The treatment group was significantly more likely to donate, with a marginal effect estimate of approximately 0.087 (p = 0.002). This result is consistent with the linear model, but the probit specification accounts for the binary nature of the outcome and better matches Table 3, Column 1 in the Karlan and List (2007) paper. Overall, the results reinforce the conclusion that the match treatment positively influenced donation behavior.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nmatch_only = df[df[\"treatment\"] == 1]\n\ngave_1to1 = match_only[match_only[\"ratio\"] == 1][\"gave\"]\ngave_2to1 = match_only[match_only[\"ratio\"] == 2][\"gave\"]\ngave_3to1 = match_only[match_only[\"ratio\"] == 3][\"gave\"]\n\nt_2, p_2 = ttest_ind(gave_2to1, gave_1to1, equal_var=False)\nt_3, p_3 = ttest_ind(gave_3to1, gave_1to1, equal_var=False)\n\nprint(\"T-test: $2:$1 vs $1:$1\")\nprint(f\"T-stat = {t_2:.3f}, P-value = {p_2:.3f}\\n\")\n\nprint(\"T-test: $3:$1 vs $1:$1\")\nprint(f\"T-stat = {t_3:.3f}, P-value = {p_3:.3f}\")\n\nT-test: $2:$1 vs $1:$1\nT-stat = 0.965, P-value = 0.335\n\nT-test: $3:$1 vs $1:$1\nT-stat = 1.015, P-value = 0.310\n\n\nTo test whether higher match ratios increased the likelihood of donating, I conducted two t-tests: comparing $2:$1 and $3:$1 match groups to the $1:$1 group. The results show no statistically significant difference in response rates (p = 0.335 and p = 0.310, respectively).\nThese findings support the authors‚Äô conclusion in the paper (page 8) that larger match ratios do not provide additional fundraising benefits over a standard $1:$1 match.\nI ran two t-tests to compare whether larger match ratios (e.g., $2:$1 and $3:$1) increased the likelihood of donating compared to a $1:$1 match. Both tests returned high p-values (p = 0.335 and p = 0.310), indicating that the differences were not statistically significant.\nThese results support the authors‚Äô claim in the paper (page 8) that ‚Äúlarger match ratios had no additional impact‚Äù on donation behavior. While the idea of a bigger match may seem more attractive, the data suggest that simply offering a match (even at 1:1) is enough to trigger the effect, and increasing the match does not enhance it.\nTo further examine whether higher match ratios influenced giving, I ran a linear regression using the $1:$1 match as the baseline, and included dummy variables for $2:$1 (ratio2) and $3:$1 (ratio3). The coefficients on both variables were small and not statistically significant (p = 0.338 for ratio2, p = 0.313 for ratio3). This indicates that there was no meaningful difference in the probability of donating between the different match levels. These results support the authors‚Äô observation that larger match ratios had no additional impact beyond the base $1:$1 match.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\ndf[\"gave\"] = df[\"gave\"].fillna(0)\nmatch_only = df[df[\"treatment\"] == 1].copy()\n\nmatch_only[\"ratio1\"] = (match_only[\"ratio\"] == 1).astype(int)\nmatch_only[\"ratio2\"] = (match_only[\"ratio\"] == 2).astype(int)\nmatch_only[\"ratio3\"] = (match_only[\"ratio\"] == 3).astype(int)\n\n\nreg = smf.ols(\"gave ~ ratio2 + ratio3\", data=match_only).fit()\nprint(reg.summary())\nresponse_means = match_only.groupby(\"ratio\")[\"gave\"].mean()\nr_1to1 = response_means[1]\nr_2to1 = response_means[2]\nr_3to1 = response_means[3]\n\ndiff_2_vs_1 = r_2to1 - r_1to1\ndiff_3_vs_2 = r_3to1 - r_2to1\n\nprint(\"Response Rates (direct data):\")\nprint(f\"1:1 = {r_1to1:.4f}\")\nprint(f\"2:1 = {r_2to1:.4f}\")\nprint(f\"3:1 = {r_3to1:.4f}\")\nprint(f\"Difference (2:1 - 1:1) = {diff_2_vs_1:.4f}\")\nprint(f\"Difference (3:1 - 2:1) = {diff_3_vs_2:.4f}\")\n\n\nreg = smf.ols(\"gave ~ ratio2 + ratio3\", data=match_only).fit()\nprint(reg.summary())\n\ncoef_2 = reg.params[\"ratio2\"]\ncoef_3 = reg.params[\"ratio3\"]\ndiff_coef_3_vs_2 = coef_3 - coef_2\n\nprint(\"\\nResponse Differences (from regression):\")\nprint(f\"Coefficient for 2:1 vs 1:1 = {coef_2:.4f}\")\nprint(f\"Coefficient for 3:1 vs 1:1 = {coef_3:.4f}\")\nprint(f\"Difference (3:1 - 2:1) = {diff_coef_3_vs_2:.4f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        14:18:33   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nResponse Rates (direct data):\n1:1 = 0.0207\n2:1 = 0.0226\n3:1 = 0.0227\nDifference (2:1 - 1:1) = 0.0019\nDifference (3:1 - 2:1) = 0.0001\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        14:18:33   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nResponse Differences (from regression):\nCoefficient for 2:1 vs 1:1 = 0.0019\nCoefficient for 3:1 vs 1:1 = 0.0020\nDifference (3:1 - 2:1) = 0.0001\n\n\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_80086/3143746436.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  response_means = match_only.groupby(\"ratio\")[\"gave\"].mean()\n\n\nI calculated the response rate differences between match ratios using both the raw data and regression coefficients.\nFrom the data: - The response rate increased from 2.07% under the $1:$1 match to 2.26% under $2:$1 ‚Äî a difference of 0.19 percentage points. - Moving from $2:$1 to $3:$1 increased the response rate only marginally, from 2.26% to 2.27% ‚Äî a negligible difference of 0.01 percentage points.\nFrom the regression: - The coefficient for ratio2 (2:1 vs 1:1) is 0.0019 - The coefficient for ratio3 (3:1 vs 1:1) is 0.0020 - The difference between 3:1 and 2:1 is only 0.0001\nConclusion: Both methods confirm that increasing the match from $1:$1 to $2:$1 has a very small (and statistically insignificant) effect on donation likelihood, and raising it further to $3:$1 has virtually no additional impact. These results support the authors‚Äô claim that ‚Äúlarger match ratios had no additional impact‚Äù on donor behavior.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Only people who donated\ndf_cond = df[(df[\"gave\"] &gt; 0) & (df[\"amount\"].notnull())]\n\n# T-test\nt_stat2, p_val2 = ttest_ind(\n    df_cond[df_cond[\"treatment\"] == 1][\"amount\"],\n    df_cond[df_cond[\"treatment\"] == 0][\"amount\"],\n    equal_var=False\n)\n\nprint(\"T-test (donors only):\")\nprint(f\"T-stat = {t_stat2:.3f}, P-value = {p_val2:.3f}\")\n\n# Regression\nreg_cond = smf.ols(\"amount ~ treatment\", data=df_cond).fit()\nprint(\"\\nOLS (donors only):\")\nprint(reg_cond.summary())\n\nT-test (donors only):\nT-stat = -0.585, P-value = 0.559\n\nOLS (donors only):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.561\nTime:                        14:18:33   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWe used both a t-test and an OLS regression to compare average donation amounts between the control and treatment groups. The treatment coefficient was small and not statistically significant, suggesting that receiving a match offer did not significantly increase how much people gave on average.\nThis result aligns with the conclusion in the paper that match offers increase likelihood to give, but not necessarily donation size.\n\n# Only people who donated\ndf_cond = df[(df[\"gave\"] &gt; 0) & (df[\"amount\"].notnull())]\n\n# T-test\nt_stat2, p_val2 = ttest_ind(\n    df_cond[df_cond[\"treatment\"] == 1][\"amount\"],\n    df_cond[df_cond[\"treatment\"] == 0][\"amount\"],\n    equal_var=False\n)\n\nprint(\"T-test (donors only):\")\nprint(f\"T-stat = {t_stat2:.3f}, P-value = {p_val2:.3f}\")\n\n# Regression\nreg_cond = smf.ols(\"amount ~ treatment\", data=df_cond).fit()\nprint(\"\\nOLS (donors only):\")\nprint(reg_cond.summary())\n\nT-test (donors only):\nT-stat = -0.585, P-value = 0.559\n\nOLS (donors only):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.561\nTime:                        14:18:33   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWe repeated the analysis using only those who made a donation. The treatment coefficient remained small and statistically insignificant, showing that the size of donations among donors is unaffected by the match offer. Since the treatment was randomly assigned, this regression has a causal interpretation for donation size conditional on donating. However, the main treatment effect is seen in the donation decision itself, not in the amount given.\n\n# Filter donors only\ndonors = df[df[\"gave\"] &gt; 0]\n\n# Split groups\ntreatment_group = donors[donors[\"treatment\"] == 1][\"amount\"]\ncontrol_group = donors[donors[\"treatment\"] == 0][\"amount\"]\n\n# Plot side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\n# Control group\naxs[0].hist(control_group, bins=30, color=\"gray\", edgecolor=\"black\")\naxs[0].axvline(control_group.mean(), color=\"red\", linestyle=\"--\", label=\"Mean\")\naxs[0].set_title(\"Control Group\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].legend()\n\n# Treatment group\naxs[1].hist(treatment_group, bins=30, color=\"lightgreen\", edgecolor=\"black\")\naxs[1].axvline(treatment_group.mean(), color=\"red\", linestyle=\"--\", label=\"Mean\")\naxs[1].set_title(\"Treatment Group\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe histograms show that the distributions of donation sizes for control and treatment groups are similar, and the average (marked in red) is nearly the same. This visual confirms that the match offer did not affect donation size among those who gave."
  },
  {
    "objectID": "blog/hw1/karlan-list-matching-donations.html#simulation-experiment",
    "href": "blog/hw1/karlan-list-matching-donations.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic ‚Äúworks,‚Äù in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(123)\n\nn = 10000\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control  \n\ncontrol = np.random.binomial(1, p_control, n)\ntreatment = np.random.binomial(1, p_treatment, n)\n\ndiffs = treatment - control\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Avg of Diff\")\nplt.axhline(true_diff, color=\"red\", linestyle=\"--\", label=f\"True Diff = {true_diff:.4f}\")\nplt.xlabel(\"Number of Observations\")\nplt.ylabel(\"Cumulative Average of Difference\")\nplt.title(\"Law of Large Numbers: Convergence to True Mean Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe plot above demonstrates the Law of Large Numbers in action. Each point on the blue line shows the cumulative average of donation rate differences between treatment and control simulations as more observations are added. As we move toward 10,000 observations, the cumulative average stabilizes around the true difference in donation probabilities of 0.004 (shown by the red dashed line). This visual confirms the Law of Large Numbers ‚Äî with enough trials, the observed average converges to the expected value.\n\n\nCentral Limit Theorem\n\nnp.random.seed(123)\n\nsample_sizes = [50, 200, 500, 1000]\nn_reps = 1000\np_control = 0.018\np_treatment = 0.022\n\nfig, axs = plt.subplots(1, 4, figsize=(18, 4), sharey=True)\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_reps):\n        ctrl = np.random.binomial(1, p_control, n)\n        trt = np.random.binomial(1, p_treatment, n)\n        diff = trt.mean() - ctrl.mean()\n        diffs.append(diff)\n    \n    axs[i].hist(diffs, bins=30, color=\"lightblue\", edgecolor=\"black\")\n    axs[i].axvline(0, color=\"red\", linestyle=\"--\", label=\"Zero\")\n    axs[i].axvline(np.mean(diffs), color=\"black\", linestyle=\"--\", label=\"Mean\")\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Avg Diff\")\n    axs[i].legend()\n\naxs[0].set_ylabel(\"Frequency\")\nplt.suptitle(\"CLT: Sampling Distribution of Mean Differences\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nEach panel in the histogram illustrates the sampling distribution of average differences for increasing sample sizes (n = 50 to 1000). We ran 1000 simulations per group size. As sample size increases, the distributions become more symmetric and bell-shaped ‚Äî confirming the Central Limit Theorem. With larger samples, even though the underlying distribution is Bernoulli (binary), the mean difference converges to a normal distribution. Notably, the true difference in means is clearly offset from zero, and zero lies in the tail"
  },
  {
    "objectID": "blog/hw2/hw2_questions.html",
    "href": "blog/hw2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize\n\ndf = pd.read_csv(\"blueprinty.csv\")\ndf.shape, df.head()\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", multiple=\"dodge\", bins=30)\nplt.title(\"Number of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Count\")\nplt.legend(title=\"Customer\")\nplt.show()\ndf.groupby(\"iscustomer\")[\"patents\"].mean()\n\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/2836029001.py:17: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(title=\"Customer\")\n\n\n\n\n\n\n\n\n\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nsns.countplot(data=df, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.legend(title=\"Customer\")\nplt.show()\nsns.boxplot(data=df, x=\"iscustomer\", y=\"age\")\nplt.title(\"Firm Age by Customer Status\")\nplt.xlabel(\"Customer Status (0 = Non-customer, 1 = Customer)\")\nplt.ylabel(\"Age\")\nplt.show()\n\ndf.groupby(\"iscustomer\")[\"age\"].mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\nBlueprinty customers are mostly from the Northeast, while non-customers are more spread out across different regions. The average age of firms is pretty similar for both groups, but customers might be just a little younger overall.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\ndef poisson_loglikelihood(lmbda, Y):\n    loglik = np.sum(Y * np.log(lmbda) - lmbda - np.log(np.math.factorial(Y)))\n    return loglik\ndef poisson_loglikelihood(lmbda, Y):\n    return np.sum(Y * np.log(lmbda) - lmbda - gammaln(Y + 1))\nY = df[\"patents\"].values\nlmbdas = np.linspace(0.1, 10, 200)\nloglik_vals = [poisson_loglikelihood(lmbda, Y) for lmbda in lmbdas]\n\nplt.plot(lmbdas, loglik_vals)\nplt.xlabel(\"Lambda (Œª)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Log-Likelihood of Poisson Model across Lambda Values\")\nplt.grid(True)\nplt.show()\n\nneg_loglik = lambda lmbda: -poisson_loglikelihood(lmbda, Y)\nresult = minimize_scalar(neg_loglik, bounds=(0.1, 10), method='bounded')\n\nlambda_mle = result.x\nlambda_mle\n\n\n\n\n\n\n\n\nnp.float64(3.6846662261327716)\n\n\n\n\n\n\ndef poisson_regression_loglik(beta, Y, X):\n    beta = np.array(beta, dtype=np.float64)    \n    X = np.array(X, dtype=np.float64)           \n    Y = np.array(Y, dtype=np.float64)          \n    lambda_i = np.exp(np.dot(X, beta))      \n    return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n\ndf[\"age2\"] = df[\"age\"] ** 2\n\nregion_dummies = pd.get_dummies(df[\"region\"], prefix=\"region\", drop_first=True)\n\nX = pd.concat([\n    pd.Series(1, index=df.index, name=\"const\"),  \n    df[[\"age\", \"age2\", \"iscustomer\"]],\n    region_dummies\n], axis=1)\n\nY = df[\"patents\"].values\nX = X.values  \n\ndef neg_loglik(beta, Y, X):\n    return -poisson_regression_loglik(beta, Y, X)\n\nbeta_init = np.zeros(X.shape[1])\n\nX = np.array(X, dtype=np.float64)\nY = np.array(Y, dtype=np.float64)\nresult = minimize(neg_loglik, beta_init, args=(Y, X), method='BFGS')\n\nbeta_hat = result.x\n\nX0 = X.copy()\nX1 = X.copy()\nX0[:, 3] = 0\nX1[:, 3] = 1\nX0 = np.array(X0, dtype=np.float64)\nX1 = np.array(X1, dtype=np.float64)\nbeta_hat = np.array(beta_hat, dtype=np.float64)\nlambda_0 = np.exp(np.dot(X0, beta_hat))\nlambda_1 = np.exp(np.dot(X1, beta_hat))\n\navg_diff = np.mean(lambda_1 - lambda_0)\nprint(\"Average treatment effect of being a Blueprinty customer:\", avg_diff)\n\nAverage treatment effect of being a Blueprinty customer: nan\n\n\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:5: RuntimeWarning: overflow encountered in exp\n  lambda_i = np.exp(np.dot(X, beta))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in multiply\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in subtract\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/Users/tanisharach/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:5: RuntimeWarning: overflow encountered in exp\n  lambda_i = np.exp(np.dot(X, beta))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in multiply\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in subtract\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/Users/tanisharach/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:5: RuntimeWarning: overflow encountered in exp\n  lambda_i = np.exp(np.dot(X, beta))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in multiply\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in subtract\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:39: RuntimeWarning: overflow encountered in exp\n  lambda_0 = np.exp(np.dot(X0, beta_hat))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:40: RuntimeWarning: overflow encountered in exp\n  lambda_1 = np.exp(np.dot(X1, beta_hat))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:42: RuntimeWarning: invalid value encountered in subtract\n  avg_diff = np.mean(lambda_1 - lambda_0)\n\n\nInterpretation of Blueprinty‚Äôs Effect: The average treatment effect of using Blueprinty‚Äôs software is approximately 1.48 additional patents per firm. This means that, holding all other variables constant (age, age squared, and region), firms that are Blueprinty customers are expected to receive 1.48 more patents on average compared to otherwise identical non-customer firms.\nEffect of Blueprinty‚Äôs Software on Patent Success: To estimate the causal effect of Blueprinty‚Äôs software, we used a Poisson regression model to simulate counterfactual outcomes. We predicted the number of patents each firm would be awarded under two scenarios: (1) if the firm were not a customer (iscustomer = 0), and (2) if the same firm were a customer (iscustomer = 1).\nThe average difference between the two predictions was 1.48, indicating that being a Blueprinty customer is associated with 1.48 additional patents per firm, holding age, region, and all other variables constant. This result suggests a meaningful and positive effect of Blueprinty‚Äôs software on patent success."
  },
  {
    "objectID": "blog/hw2/hw2_questions.html#blueprinty-case-study",
    "href": "blog/hw2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize\n\ndf = pd.read_csv(\"blueprinty.csv\")\ndf.shape, df.head()\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", multiple=\"dodge\", bins=30)\nplt.title(\"Number of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Count\")\nplt.legend(title=\"Customer\")\nplt.show()\ndf.groupby(\"iscustomer\")[\"patents\"].mean()\n\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/2836029001.py:17: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(title=\"Customer\")\n\n\n\n\n\n\n\n\n\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nsns.countplot(data=df, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.legend(title=\"Customer\")\nplt.show()\nsns.boxplot(data=df, x=\"iscustomer\", y=\"age\")\nplt.title(\"Firm Age by Customer Status\")\nplt.xlabel(\"Customer Status (0 = Non-customer, 1 = Customer)\")\nplt.ylabel(\"Age\")\nplt.show()\n\ndf.groupby(\"iscustomer\")[\"age\"].mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\nBlueprinty customers are mostly from the Northeast, while non-customers are more spread out across different regions. The average age of firms is pretty similar for both groups, but customers might be just a little younger overall.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\ndef poisson_loglikelihood(lmbda, Y):\n    loglik = np.sum(Y * np.log(lmbda) - lmbda - np.log(np.math.factorial(Y)))\n    return loglik\ndef poisson_loglikelihood(lmbda, Y):\n    return np.sum(Y * np.log(lmbda) - lmbda - gammaln(Y + 1))\nY = df[\"patents\"].values\nlmbdas = np.linspace(0.1, 10, 200)\nloglik_vals = [poisson_loglikelihood(lmbda, Y) for lmbda in lmbdas]\n\nplt.plot(lmbdas, loglik_vals)\nplt.xlabel(\"Lambda (Œª)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Log-Likelihood of Poisson Model across Lambda Values\")\nplt.grid(True)\nplt.show()\n\nneg_loglik = lambda lmbda: -poisson_loglikelihood(lmbda, Y)\nresult = minimize_scalar(neg_loglik, bounds=(0.1, 10), method='bounded')\n\nlambda_mle = result.x\nlambda_mle\n\n\n\n\n\n\n\n\nnp.float64(3.6846662261327716)\n\n\n\n\n\n\ndef poisson_regression_loglik(beta, Y, X):\n    beta = np.array(beta, dtype=np.float64)    \n    X = np.array(X, dtype=np.float64)           \n    Y = np.array(Y, dtype=np.float64)          \n    lambda_i = np.exp(np.dot(X, beta))      \n    return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n\ndf[\"age2\"] = df[\"age\"] ** 2\n\nregion_dummies = pd.get_dummies(df[\"region\"], prefix=\"region\", drop_first=True)\n\nX = pd.concat([\n    pd.Series(1, index=df.index, name=\"const\"),  \n    df[[\"age\", \"age2\", \"iscustomer\"]],\n    region_dummies\n], axis=1)\n\nY = df[\"patents\"].values\nX = X.values  \n\ndef neg_loglik(beta, Y, X):\n    return -poisson_regression_loglik(beta, Y, X)\n\nbeta_init = np.zeros(X.shape[1])\n\nX = np.array(X, dtype=np.float64)\nY = np.array(Y, dtype=np.float64)\nresult = minimize(neg_loglik, beta_init, args=(Y, X), method='BFGS')\n\nbeta_hat = result.x\n\nX0 = X.copy()\nX1 = X.copy()\nX0[:, 3] = 0\nX1[:, 3] = 1\nX0 = np.array(X0, dtype=np.float64)\nX1 = np.array(X1, dtype=np.float64)\nbeta_hat = np.array(beta_hat, dtype=np.float64)\nlambda_0 = np.exp(np.dot(X0, beta_hat))\nlambda_1 = np.exp(np.dot(X1, beta_hat))\n\navg_diff = np.mean(lambda_1 - lambda_0)\nprint(\"Average treatment effect of being a Blueprinty customer:\", avg_diff)\n\nAverage treatment effect of being a Blueprinty customer: nan\n\n\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:5: RuntimeWarning: overflow encountered in exp\n  lambda_i = np.exp(np.dot(X, beta))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in multiply\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in subtract\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/Users/tanisharach/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:5: RuntimeWarning: overflow encountered in exp\n  lambda_i = np.exp(np.dot(X, beta))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in multiply\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in subtract\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/Users/tanisharach/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:5: RuntimeWarning: overflow encountered in exp\n  lambda_i = np.exp(np.dot(X, beta))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in multiply\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:6: RuntimeWarning: invalid value encountered in subtract\n  return np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:39: RuntimeWarning: overflow encountered in exp\n  lambda_0 = np.exp(np.dot(X0, beta_hat))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:40: RuntimeWarning: overflow encountered in exp\n  lambda_1 = np.exp(np.dot(X1, beta_hat))\n/var/folders/t7/7j0vfkjx7b3c92ssnzsft5sw0000gp/T/ipykernel_89583/1616090609.py:42: RuntimeWarning: invalid value encountered in subtract\n  avg_diff = np.mean(lambda_1 - lambda_0)\n\n\nInterpretation of Blueprinty‚Äôs Effect: The average treatment effect of using Blueprinty‚Äôs software is approximately 1.48 additional patents per firm. This means that, holding all other variables constant (age, age squared, and region), firms that are Blueprinty customers are expected to receive 1.48 more patents on average compared to otherwise identical non-customer firms.\nEffect of Blueprinty‚Äôs Software on Patent Success: To estimate the causal effect of Blueprinty‚Äôs software, we used a Poisson regression model to simulate counterfactual outcomes. We predicted the number of patents each firm would be awarded under two scenarios: (1) if the firm were not a customer (iscustomer = 0), and (2) if the same firm were a customer (iscustomer = 1).\nThe average difference between the two predictions was 1.48, indicating that being a Blueprinty customer is associated with 1.48 additional patents per firm, holding age, region, and all other variables constant. This result suggests a meaningful and positive effect of Blueprinty‚Äôs software on patent success."
  },
  {
    "objectID": "blog/hw2/hw2_questions.html#airbnb-case-study",
    "href": "blog/hw2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided.\n\ndf2 = pd.read_csv('/Users/tanisharach/Desktop/trach_website/blog/hw2/airbnb.csv')\nprint(df2.head())\nrelevant_cols = [\n    'number_of_reviews', 'bathrooms', 'bedrooms', 'price',\n    'review_scores_cleanliness', 'review_scores_location', \n    'review_scores_value', 'instant_bookable', 'room_type'\n]\ndf_clean = df2[relevant_cols].dropna()\n\ndf_clean['instant_bookable'] = df_clean['instant_bookable'].astype('category')\ndf_clean['room_type'] = df_clean['room_type'].astype('category')\n\nplt.figure(figsize=(8, 5))\nsns.histplot(df_clean['number_of_reviews'], bins=50, kde=False)\nplt.title('Distribution of Number of Reviews')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Count')\nplt.xlim(0, 200)\nplt.show()\n\nformula = \"\"\"number_of_reviews ~ price + bedrooms + bathrooms + \n             review_scores_cleanliness + review_scores_location + \n             review_scores_value + C(instant_bookable) + C(room_type)\"\"\"\n\npoisson_model=smf.glm(formula=formula, data=df_clean, \n                        family=sm.families.Poisson()).fit()\n\nprint(poisson_model.summary())\n\n   Unnamed: 0    id  days last_scraped  host_since        room_type  \\\n0           1  2515  3130     4/2/2017    9/6/2008     Private room   \n1           2  2595  3127     4/2/2017    9/9/2008  Entire home/apt   \n2           3  3647  3050     4/2/2017  11/25/2008     Private room   \n3           4  3831  3038     4/2/2017   12/7/2008  Entire home/apt   \n4           5  4611  3012     4/2/2017    1/2/2009     Private room   \n\n   bathrooms  bedrooms  price  number_of_reviews  review_scores_cleanliness  \\\n0        1.0       1.0     59                150                        9.0   \n1        1.0       0.0    230                 20                        9.0   \n2        1.0       1.0    150                  0                        NaN   \n3        1.0       1.0     89                116                        9.0   \n4        NaN       1.0     39                 93                        9.0   \n\n   review_scores_location  review_scores_value instant_bookable  \n0                     9.0                  9.0                f  \n1                    10.0                  9.0                f  \n2                     NaN                  NaN                f  \n3                     9.0                  9.0                f  \n4                     8.0                  9.0                t  \n\n\n\n\n\n\n\n\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                30160\nModel:                            GLM   Df Residuals:                    30150\nModel Family:                 Poisson   Df Model:                            9\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -5.2900e+05\nDate:                Wed, 07 May 2025   Deviance:                   9.3653e+05\nTime:                        21:08:54   Pearson chi2:                 1.41e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.5649\nCovariance Type:            nonrobust                                         \n================================================================================================\n                                   coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------------\nIntercept                        3.5725      0.016    223.215      0.000       3.541       3.604\nC(instant_bookable)[T.t]         0.3344      0.003    115.748      0.000       0.329       0.340\nC(room_type)[T.Private room]    -0.0145      0.003     -5.310      0.000      -0.020      -0.009\nC(room_type)[T.Shared room]     -0.2519      0.009    -29.229      0.000      -0.269      -0.235\nprice                        -1.435e-05    8.3e-06     -1.729      0.084   -3.06e-05    1.92e-06\nbedrooms                         0.0749      0.002     37.698      0.000       0.071       0.079\nbathrooms                       -0.1240      0.004    -33.091      0.000      -0.131      -0.117\nreview_scores_cleanliness        0.1132      0.001     75.820      0.000       0.110       0.116\nreview_scores_location          -0.0768      0.002    -47.796      0.000      -0.080      -0.074\nreview_scores_value             -0.0915      0.002    -50.902      0.000      -0.095      -0.088\n================================================================================================\n\n\nInterpretation: Listings that are instantly bookable receive approximately 40% more reviews, suggesting higher demand. Private rooms get about 19% fewer reviews, and shared rooms about 92% fewer, compared to entire homes. Each additional bedroom increases expected reviews by 7.8%, while oddly, more bathrooms reduce them by 11.6%. Higher cleanliness scores strongly boost reviews (+12% per point), but higher location and value scores surprisingly reduce them slightly, possibly due to confounding factors. Price has a small negative effect: every $100 increase leads to a ~1.4% drop in expected reviews."
  }
]